# ðŸ§  Niche Fine-Tuned Open Source Model  
### Fine-tuning TinyLlama with LoRA to build a FastAPI expert assistant

This project demonstrates how to fine-tune a small open-source LLM on a **very specific niche domain**.  
In this case, the niche is **FastAPI**, and we train a TinyLlama model to behave like a FastAPI expert that answers framework-specific questions with accurate explanations and code examples.

The project includes:
- A custom dataset (JSONL) of FastAPI questions & expert answers  
- LoRA fine-tuning using `transformers` + `peft`  
- A complete training pipeline (local + Colab compatible)  
- An inference script and interactive CLI  
- Clean modular project structure for easy reuse

---

## ðŸš€ Features

âœ” Fine-tunes **TinyLlama-1.1B-Chat** using **LoRA**  
âœ” Custom **FastAPI Q&A dataset**  
âœ” Works on **Google Colab GPU**  
âœ” Modular Python design (`src/config`, `dataset`, `train_lora`, `inference`)  
âœ” Simple CLI to chat with the fine-tuned model  
âœ” Loads & runs the model locally after training  

---

## ðŸ“‚ Project Structure

```text
niche_finetuned_model/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ fastapi_qa_train.jsonl
â”‚ â””â”€â”€ fastapi_qa_eval.jsonl
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py # Model paths & hyperparameters
â”‚ â”œâ”€â”€ dataset.py # Loads + tokenizes JSONL dataset
â”‚ â”œâ”€â”€ train_lora.py # LoRA training script
â”‚ â”œâ”€â”€ inference.py # Load + generate answers
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ main.py # CLI interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ§ª Training the Model (LoRA Fine-Tuning)

- You can train locally or in Colab.
- Run training: python -m src.train_lora

This will:

- Load TinyLlama
- Load the FastAPI dataset
- Apply LoRA adapters
- Train for a few epochs
- Save the fine-tuned model to: outputs/fastapi_tinyllama_lora/

## ðŸ’¬ Using the Fine-Tuned Model

- Run the interactive CLI: python main.py
- Example usage:

You: How do I define a POST endpoint in FastAPI?
Assistant: Use @app.post and a Pydantic model...

## ðŸ”® Future Enhancements

- Expand dataset with hundreds more Q&A samples
- Add RAG support for external FastAPI docs
- Package final model for HF Hub
- Create a Streamlit UI for the niche assistant
- Add quantized inference (GGUF / GPTQ) for faster local use

## Author

SYED WALEED AHMED